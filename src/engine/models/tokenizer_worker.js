// == Gemini Token Counter (v1.0) - tokenizer_worker.js ==
// ... (é¡¶éƒ¨ä»£ç çœç•¥)

self.onmessage = async (event) => {
    const message = event.data;
    const TOTAL_STEPS = 5; // æ­¥éª¤å‡å°‘ï¼Œå› ä¸ºä¸å† Fetch JSON
    
    if (message.type === 'INIT') {
        try {
            // ... (æ­¥éª¤ 1-3 ä¿æŒä¸å˜ï¼Œç”¨äºåŠ è½½ transformers.js å’Œè®¾ç½® WASM è·¯å¾„)
            
            postLoadingStatus(4, TOTAL_STEPS, 'æ­£åœ¨åˆå¹¶é…ç½®å¹¶åˆå§‹åŒ–åˆ†è¯å™¨...');

            // ğŸ’¥ ä¿®å¤ 3: ç›´æ¥ä½¿ç”¨ä¸»çº¿ç¨‹ä¼ é€’çš„ JSON æ•°æ®å¯¹è±¡
            const [tokenizer_json, tokenizer_config, special_tokens] = [
                message.tokenizerJsonData,
                message.tokenizerConfigData,
                message.specialTokensData
            ];
            
            if (!tokenizer_json || !tokenizer_config || !special_tokens) {
                 throw new Error("JSON æ•°æ®ä¼ é€’å¤±è´¥ï¼Œå†…å®¹ä¸ºç©ºã€‚");
            }

            // 5. åˆå§‹åŒ– GemmaTokenizer (WASM åŠ è½½åœ¨è¿™é‡Œå‘ç”Ÿ)
            const mergedConfig = {
                ...tokenizer_config, 
                ...special_tokens,
                tokenizer: tokenizer_json 
            };
            
            tokenizerInstance = await new self.Xenova.GemmaTokenizer(mergedConfig);
            isInitialized = true;
            
            postLoadingStatus(5, TOTAL_STEPS, 'åˆ†è¯å™¨åˆå§‹åŒ–æˆåŠŸï¼');
            
            self.postMessage({ type: 'WORKER_STATUS', status: 'READY' });

        } catch (e) {
            console.error("Worker åˆ†è¯å™¨åŠ è½½å¤±è´¥:", e);
            self.postMessage({ type: 'WORKER_STATUS', status: 'ERROR', error: e.message || "Workerå†…éƒ¨å‘ç”Ÿæœªæ•è·çš„é”™è¯¯" });
        }
    } else if (message.type === 'ENCODE_TEXT') {
        // ... (ç¼–ç é€»è¾‘çœç•¥)
    }
};

// ... (é¢„çƒ­çŠ¶æ€çœç•¥)